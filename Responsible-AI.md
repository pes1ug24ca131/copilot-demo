# Responsible AI Guidelines

These guidelines ensure that AI-assisted coding (e.g., GitHub Copilot) is used safely, ethically, and responsibly within this project.

---

## 1. Reviewing and Validating AI-Generated Code
- Always read and understand any code generated by AI before accepting it.
- Verify the logic with tests, type checks, or manual review.
- Watch for subtle bugs such as incorrect edge cases or inefficient algorithms.
- Avoid blindly relying on AI for critical or sensitive parts of the system.

---

## 2. Handling Sensitive Data Securely
- Never allow AI to insert API keys, passwords, tokens, or private credentials into source code.
- Store all secrets in environment variables or encrypted secrets (GitHub Secrets, .env files not committed).
- Review AI-generated code for any accidental exposure of sensitive data.
- Immediately rotate any credentials that may have been leaked.

---

## 3. Acknowledging AI Contributions Ethically
- Document when AI tools (like Copilot) contributed significantly to a file or function.
- Ensure that human contributors review and approve all changes.
- Avoid presenting AI-generated code as entirely original without oversight.
- Follow licensing rules: do not accept AI suggestions that appear copied from unknown or incompatible open-source sources.

---

## 4. Ensuring Safe Automation
- Use automated tools (CI tests, linters, static analyzers) to validate AI-generated code.
- Require peer reviews for pull requests that include AI-assisted changes.
- Ensure that automation workflows do not execute unsafe or unverified code.

---

## 5. Continuous Improvement
- Regularly update practices as AI tools evolve.
- Encourage contributors to report unsafe or questionable AI-generated code.
- Monitor new developments in AI ethics and integrate them into this document.

---

By following these guidelines, this project ensures that AI assistance improves productivity **without compromising security, quality, or integrity**.
